{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b082ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4ebdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# короче этот датасет уже по-другому загружать надо\n",
    "celeba_bldr = tfds.builder('celeb_a', data_dir='~/tensorflow_datasets')\n",
    "celeba_bldr.download_and_prepare(download_config=tfds.download.DownloadConfig(manual_dir='~/tensorflow_datasets/downloads/manual'))\n",
    "celeba = celeba_bldr.as_dataset(shuffle_files=False)\n",
    "print(celeba.keys())\n",
    "\n",
    "celeba_train = celeba['train']\n",
    "celeba_valid = celeba['validation']\n",
    "celeba_test = celeba['test']\n",
    "\n",
    "def count_items(ds):\n",
    "    n = 0\n",
    "    for _ in ds:\n",
    "        n += 1\n",
    "    return n\n",
    "\n",
    "print('Train set:  {}'.format(count_items(celeba_train)))\n",
    "print('Validation: {}'.format(count_items(celeba_valid)))\n",
    "print('Test set:   {}'.format(count_items(celeba_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd740996",
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_train = celeba_train.take(16000)\n",
    "celeba_valid = celeba_valid.take(1000)\n",
    "\n",
    "print('Train set:  {}'.format(count_items(celeba_train)))\n",
    "print('Validation: {}'.format(count_items(celeba_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d6cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# примеры настройки изображений\n",
    "\n",
    "examples = []\n",
    "for example in celeba_train.take(5):\n",
    "    examples.append(example['image'])\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8.5))\n",
    "\n",
    "## Column 1: cropping to a bounding-box\n",
    "ax = fig.add_subplot(2, 5, 1)\n",
    "ax.imshow(examples[0])\n",
    "ax = fig.add_subplot(2, 5, 6)\n",
    "ax.set_title('Crop to a \\nbounding-box', size=15)\n",
    "img_cropped = tf.image.crop_to_bounding_box(\n",
    "    examples[0], 50, 20, 128, 128)\n",
    "ax.imshow(img_cropped)\n",
    "\n",
    "## Column 2: flipping (horizontally)\n",
    "ax = fig.add_subplot(2, 5, 2)\n",
    "ax.imshow(examples[1])\n",
    "ax = fig.add_subplot(2, 5, 7)\n",
    "ax.set_title('Flip (horizontal)', size=15)\n",
    "img_flipped = tf.image.flip_left_right(examples[1])\n",
    "ax.imshow(img_flipped)\n",
    "\n",
    "## Column 3: adjust contrast\n",
    "ax = fig.add_subplot(2, 5, 3)\n",
    "ax.imshow(examples[2])\n",
    "ax = fig.add_subplot(2, 5, 8)\n",
    "ax.set_title('Adjust constrast', size=15)\n",
    "img_adj_contrast = tf.image.adjust_contrast(\n",
    "    examples[2], contrast_factor=2)\n",
    "ax.imshow(img_adj_contrast)\n",
    "\n",
    "## Column 4: adjust brightness\n",
    "ax = fig.add_subplot(2, 5, 4)\n",
    "ax.imshow(examples[3])\n",
    "ax = fig.add_subplot(2, 5, 9)\n",
    "ax.set_title('Adjust brightness', size=15)\n",
    "img_adj_brightness = tf.image.adjust_brightness(\n",
    "    examples[3], delta=0.3)\n",
    "ax.imshow(img_adj_brightness)\n",
    "\n",
    "## Column 5: cropping from image center \n",
    "ax = fig.add_subplot(2, 5, 5)\n",
    "ax.imshow(examples[4])\n",
    "ax = fig.add_subplot(2, 5, 10)\n",
    "ax.set_title('Centeral crop\\nand resize', size=15)\n",
    "img_center_crop = tf.image.central_crop(\n",
    "    examples[4], 0.7)\n",
    "img_resized = tf.image.resize(\n",
    "    img_center_crop, size=(218, 178))\n",
    "ax.imshow(img_resized.numpy().astype('uint8'))\n",
    "\n",
    "# plt.savefig('figures/15_14.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 12))\n",
    "\n",
    "for i,example in enumerate(celeba_train.take(3)):\n",
    "    image = example['image']\n",
    "\n",
    "    ax = fig.add_subplot(3, 4, i*4+1)\n",
    "    ax.imshow(image)\n",
    "    if i == 0:\n",
    "        ax.set_title('Orig.', size=15)\n",
    "\n",
    "    ax = fig.add_subplot(3, 4, i*4+2)\n",
    "    img_crop = tf.image.random_crop(image, size=(178, 178, 3))\n",
    "    ax.imshow(img_crop)\n",
    "    if i == 0:\n",
    "        ax.set_title('Step 1: Random crop', size=15)\n",
    "\n",
    "    ax = fig.add_subplot(3, 4, i*4+3)\n",
    "    img_flip = tf.image.random_flip_left_right(img_crop)\n",
    "    ax.imshow(tf.cast(img_flip, tf.uint8))\n",
    "    if i == 0:\n",
    "        ax.set_title('Step 2: Random flip', size=15)\n",
    "\n",
    "    ax = fig.add_subplot(3, 4, i*4+4)\n",
    "    img_resize = tf.image.resize(img_flip, size=(128, 128))\n",
    "    ax.imshow(tf.cast(img_resize, tf.uint8))\n",
    "    if i == 0:\n",
    "        ax.set_title('Step 3: Resize', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example, size=(64, 64), mode='train'):\n",
    "    image = example['image']\n",
    "    label = example['attributes']['Male']\n",
    "    if mode == 'train':\n",
    "        image_cropped = tf.image.random_crop(\n",
    "            image, size=(178, 178, 3))\n",
    "        image_resized = tf.image.resize(\n",
    "            image_cropped, size=size)\n",
    "        image_flip = tf.image.random_flip_left_right(\n",
    "            image_resized)\n",
    "        return (image_flip/255.0, tf.cast(label, tf.int32))\n",
    "    \n",
    "    else:\n",
    "        image_cropped = tf.image.crop_to_bounding_box(\n",
    "            image, offset_height=20, offset_width=0,\n",
    "            target_height=178, target_width=178)\n",
    "        image_resized = tf.image.resize(\n",
    "            image_cropped, size=size)\n",
    "        return (image_resized/255.0, tf.cast(label, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f764ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 1000\n",
    "IMAGE_SIZE = (64, 64)\n",
    "steps_per_epoch = np.ceil(16000/BATCH_SIZE)\n",
    "print(steps_per_epoch)\n",
    "\n",
    "ds_train = celeba_train.map(\n",
    "    lambda x: preprocess(x, size=IMAGE_SIZE, mode='train'))\n",
    "ds_train = ds_train.shuffle(buffer_size=BUFFER_SIZE)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "\n",
    "ds_valid = celeba_valid.map(\n",
    "    lambda x: preprocess(x, size=IMAGE_SIZE, mode='eval'))\n",
    "ds_valid = ds_valid.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1813a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(\n",
    "        32, (3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(\n",
    "        64, (3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(\n",
    "        128, (3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(\n",
    "        256, (3, 3), padding='same', activation='relu'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200216de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compute_output_shape(input_shape=(None, 64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10470d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.GlobalAveragePooling2D()) # объединение по глобальному среднему\n",
    "model.compute_output_shape(input_shape=(None, 64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1266bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(1, activation=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305a67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, 64, 64, 3))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c04f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(ds_train, validation_data=ds_valid, \n",
    "                    epochs=20, steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56495cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "x_arr = np.arange(len(hist['loss'])) + 1\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(x_arr, hist['loss'], '-o', label='Train loss')\n",
    "ax.plot(x_arr, hist['val_loss'], '--<', label='Validation loss')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Loss', size=15)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(x_arr, hist['accuracy'], '-o', label='Train acc.')\n",
    "ax.plot(x_arr, hist['val_accuracy'], '--<', label='Validation acc.')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Accuracy', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895c3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = celeba_test.map(\n",
    "    lambda x:preprocess(x, size=IMAGE_SIZE, mode='eval')).batch(32)\n",
    "results = model.evaluate(ds_test, verbose=0)\n",
    "print('Test Acc: {:.2f}%'.format(results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9334b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# дообучаем\n",
    "\n",
    "history = model.fit(ds_train, validation_data=ds_valid, \n",
    "                    epochs=30, initial_epoch=20,\n",
    "                    steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b2a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2 = history.history\n",
    "x_arr = np.arange(len(hist['loss'] + hist2['loss']))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(x_arr, hist['loss']+hist2['loss'], \n",
    "        '-o', label='Train Loss')\n",
    "ax.plot(x_arr, hist['val_loss']+hist2['val_loss'],\n",
    "        '--<', label='Validation Loss')\n",
    "ax.legend(fontsize=15)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(x_arr, hist['accuracy']+hist2['accuracy'], \n",
    "        '-o', label='Train Acc.')\n",
    "ax.plot(x_arr, hist['val_accuracy']+hist2['val_accuracy'], \n",
    "        '--<', label='Validation Acc.')\n",
    "ax.legend(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9290646",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = celeba_test.map(\n",
    "    lambda x:preprocess(x, size=IMAGE_SIZE, mode='eval')).batch(32)\n",
    "results = model.evaluate(ds_test, verbose=0)\n",
    "print('Test Acc: {:.2f}%'.format(results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e99438",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds_test.unbatch().take(10)\n",
    "\n",
    "pred_logits = model.predict(ds.batch(10))\n",
    "probas = tf.sigmoid(pred_logits)\n",
    "probas = probas.numpy().flatten()*100\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "for j,example in enumerate(ds):\n",
    "    ax = fig.add_subplot(2, 5, j+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(example[0])\n",
    "    if example[1].numpy() == 1:\n",
    "        label='Male'\n",
    "    else:\n",
    "        label = 'Female'\n",
    "    ax.text(\n",
    "        0.5, -0.15, \n",
    "        'GT: {:s}\\nPr(Male)={:.0f}%'.format(label, probas[j]), \n",
    "        size=16, \n",
    "        horizontalalignment='center',\n",
    "        verticalalignment='center', \n",
    "        transform=ax.transAxes)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21610ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/celeba-cnn.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
